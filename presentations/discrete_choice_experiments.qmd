---
title: "Discrete Choice Experiments"
format: 
  revealjs:
    theme: simple
    multiplex: true
    self_contained: true
editor: source
bibliography: DCE.bib
suppress-bibliography: false
---

# Today's agenda {.smaller}

We'll take a look at our latest progress towards implementing a discrete choice experiment while covering a couple of related topics:


::: incremental

-   Thanks everyone who helped test the first beta experiment!!
-   Background on Discrete Choice Experiments - that's a mouthful, let's call them DCEs
-   Attributes and levels – the assumptions and traps we’re trying to avoid.
-   Revisit the survey - our decisions so far.
-   Take an updated survey - nu på svenska!
-   Break
-   Discussion and feedback
:::

::: notes

We will get to the survey - but focus today is more geared towards the experiment itself.  Since many of the details relate intimately with the survey design, it will be helpful for us to get a little bit of a background to contextualize our study.

:::

## What's the plan?

::: incremental

- Experiment will be included in the 2024 RELOC-AGE Prospective follow-up survey
- Yet to be determined exactly how we deliver this experiment
- Link to experiment after completing the main survey... or
- Separate email to respondents at different time...
- Who are the respondents?

:::

## RELOC-AGE Prospective 

```{r map, eval=TRUE ,warning=FALSE, include=TRUE, widget.layout.height = "calc(100vh - 90px)"}
library(leaflet)
library(kableExtra)
address_lat_lon <- readRDS("discrete_choice_experiments_files/coords.rds") 

leaflet(address_lat_lon,width = "100%" ) %>%
  addTiles() %>%  # Add default OpenStreetMap map tiles
  addMarkers(~lon,
             ~lat,
             popup="Respondents",
             #clusterOptions = markerClusterOptions()
             ) 

```


## Descriptives 

![](discrete_choice_experiments_files/sum_stat.jpg)

## Housing attributes

![](discrete_choice_experiments_files/attributes.jpg)



## Development of the research aim

::: incremental
- We know many physical housing attributes that respondents find important from follow-up survey (balcony, elevator, single floor, etc.)
- We know less about the preferred attributes dealing with ___location___.
- Where do people want to be situated?
- Does proximity to certain services or location matter?
- If so, which locational attributes are most important?
:::

::: notes

over half of respondents listed good parking facilities as important. 45% that the dwelling is close to public transportation.

:::

## Aim and RQ's

Will get some fine tuning, but along the lines of...

::: incremental
- "The overall aim is to explore the factors which matters most for the choice of another dwelling among people aged 55 years or more, interested in relocation.”
- "The overarching aim of this paper is to explore heterogeneous locational preferences of those aged 55 years or more and interested in relocation"
- In order to do this, we will conduct a Discrete Choice Experiment to elicit preferences of those surveyed.
- So what exactly ___is___ a Discrete Choice Experiment??!!

:::

::: notes
Which brings us to the experiments
:::

## Discrete Choice Experiments

-   Used in various fields, including economics, marketing, and healthcare, to understand individuals' preferences and decision-making processes.
-   The primary goal of a DCE is to elicit and quantify individuals' preferences for different attributes or features of a product, service, or policy by presenting them with a series of choice scenarios.

::: notes
Key word here is "elicit"
:::

## Choice experiments

-   DCE's fall into the more broader group of choice experiments.
-   When we make a choice, we show a **preference**.
-   Preferences can be construed as **stated** or **revealed**.

## Stated vs. revealed preferences{.smaller}


::: incremental
-   Stated: Researchers gather information by **directly** asking individuals about their preferences, opinions, or choices through interviews, surveys, or other data collection methods.
- "Do you find the distance to public transportation (most) important when considering a new apartment?"

-   Revealed: Researchers analyze real-world data, such as consumer purchasing behavior, travel patterns, or **observed choices**, to uncover implicit preferences.

- "Thanks for participating in the experiment! From your actions, we observe that you found distance to transportation least important, compared to..."
:::


## Discrete Choice Experiments{.smaller}

::: incremental
-   Discrete choice models operate within a framework of rational choice; that is, it is assumed that when confronted with a discrete set of options, people choose the option of **maximal benefit or utility**.
-   It follows that the choice is a function of the utility found in each attributes found in options presented.
-   By asking (forcing) many respondents to choose between alternatives in a __controlled experiment__ we can elicit preferences from the **sample population.**
-   We can then perform statistical inference about the functional parameters. 
::: 

## DCEs advantages

- Mimics real life decision-making: reduces biases associated with self-reporting
- Can implement an economic factor and to derive a "willingness to pay" estimate.


## Example - Cancer treatment options
![](discrete_choice_experiments_files/dce_patient.jpg)

## Example - Willingnes to pay for organic?

![](discrete_choice_experiments_files/dce_meat.jpg)


## DCE's in Housing studies{.smaller}


::: incremental
- "Best living concepts for elderly homeowners: combining 
a stated choice experiment with architectural design" [@ossokinaBestLivingConcepts2020]
- "Reference-dependent housing choice behaviour:
why are older people reluctant to move?" [@ossokinaReferencedependentHousingChoice2022a]
- "Measuring heterogeneous preferences for residential amenities" [@caplanMeasuringHeterogeneousPreferences2021]
 - "Rural residential preferences for house design and location: insights from
a discrete choice experiment applied to Ireland"[@bullockRuralResidentialPreferences2011]
::: 

## Process

::: incremental
- Let's look next on how we can go about conducting a DCE.
- Helpful for understanding our particular considerations
- Keep in mind that we are designing a __Controlled Experiment__!
- The aim is to present feasible alternatives with minimal bias in the choice sets.
- The alternatives should only differ by the levels of the attributes.
::: 

## Process in a nutshell


```{r , echo=FALSE, warning=FALSE}
library(DiagrammeR)
grViz("digraph flowchart {
      # node definitions with substituted label text
      node [fontname = Helvetica, shape = rectangle]        
      tab1 [label = '@@1']
      tab2 [label = '@@2']
      tab3 [label = '@@3']
      tab4 [label = '@@4']
      tab5 [label = '@@5']

      # edge definitions with the node IDs
      tab1 -> tab2 -> tab3 -> tab4 -> tab5;
      }

      [1]: 'Select attributes and their levels'
      [2]: 'Survey design - creates optimal mix/number of choice sets'
      [3]: 'Administer survey - using choice sets from the design'
      [4]: 'Analyze the data - estimate models'
      [5]: 'Present/interpret the results - tables/figures on coeffcient sizes'
      ")
```

## Attributes and levels

- Arguably the most difficult aspect of conducting a DCE.
- How many attributes should we include?
- What kind of attributes can we include?
- What should the levels of the attributes be?

## Attributes - Properties{.smaller}

Below are some attribute property guidelines taken from the literature. 

* The greater number of attributes, the greater the cognitive difficulty of completing a DCE. [@manghamHowNotDesigning2009]

* Increased age would tend to exacerbate the cognitive burden of the DCE, highlighting the need to address the complexity of the experiment in order to obtain valid and reliable responses [@himmlerWhatWorksBetter2021]

* There should be no more than 10 to ensure respondents are able to consider all attributes listed [@himmlerWhatWorksBetter2021]

* Definitions of the attributes should not be ambiguous and should be __easily interpretable__ by the respondents. [@deshazoDesigningChoiceSets2002]

* the attributes presented should be viable options for all respondents ( Or at least for  __most__ ).

* The experiments pivots around utility theory.  __All attributes and levels should have a positive utility__.

## Attributes - rules of thumb{.smaller}


- Regarding utility assumptions and viability concerns, we would like to avoid presenting choices to the respondents which are clearly biased.

- In other words, we want to avoid any potential combination of attributes that creates an obvious "good" vs "bad" scenario where any rational actor would choose the "good" option, regardless of their individual utility preferences. 

## Attributes - (more) rules of thumb{.smaller}

- We should avoid attributes that are only relevant to particular segments of the sample.  For example, "Is wheelchair accessible" would be a poor attribute as wheelchair users would certainly always choose this option, and non-wheelchair users would be gain no utility in choosing this option.

- Dichotomous levels should be avoided.  Firstly, as every combination of attributes and levels will be presented in the survey, combinations with combined negative levels with make their way into the choice sets creating options which no rational actor would choose.  

- Second, as the experiment assumptions are situated in utility theory with trade-offs of utility, we want levels to contain some sort of utility to actually "trade off". An option with no utility will never be chosen and this works against the experiment.  

## Number of attribues and levels

- Considering our sample size, how many attributes/level combinations should we use?
- No sample size estimator here - there are many factors to consider.
- How many respondents will we have?



```{r, echo=FALSE, results='asis'}
library(DiagrammeR)
DiagrammeR::grViz("digraph {
  
graph[layout = dot, rankdir = LR]


a   [label = 'Baseline\nSpring 2021\nn=1964'] 
b [label = 'Follow-up\nSpring 2022\nn=1254'] 
c  [label = '2nd follow-up\nSpring 2024\nn=???', color = red, fontcolor = red] 


a -> b -> c
}")
```

::: notes

Exact sample sizes depend on variations in missing data

:::


## Number of attribues and levels

- Considering our sample size, how many attributes/level combinations should we use?
- No sample size estimator here - there are many factors to consider.
- One way, simulate some answers and perform the analysis - what happens to the SE's?

## Standard errors - 

![](discrete_choice_experiments_files/sample_size.jpg)


## Survey design?{.smaller}

::: incremental
- We now have some guidelines and more information on attributes
- What is the survey design?
- Once we've selected our attributes and levels we need to consider how many choice sets each respondent will take.
- If we have five attributes with 3 levels each, that's 5x5x5= **125** combinations!!!
- We can't ask respondents to complete 125 choice sets!!
- We can use some dimensional-reduction techniques to get the same statistical power without asking an unreasonable number of questions.
::: 

## Survey design - options

![](discrete_choice_experiments_files/design.jpg)

## Administer the survey


- A consequence of the dimension-reduction method is we need to specify specific versions of the choice set for each respondent.
- Our survey provider informed us they could not do this!

## Self-hosting an opensource survey framework{.smaller}

::: incremental
- Formr: an opensource survey framework built on R that allows users to conduct very complex surveys for free.
- It's popular
- Too popular - no more users
- The code for their framework is opensource.
- Need to set up a server, database, functioning app, computational instance, website, interface, and learn at least the basics of a few programming languages...
- We did that and now have a workable solution - If you're interested ask me later!
::: 

## Analyse the results
::: incremental
- Approach is to use a random utility model a la [@hensherAppliedChoiceAnalysis2015]:
- Essentially, a multi-nominal logit model that we are familiar with.
- Straight-forward to estimate
- Check out the beginings of the [Discrete choice paper](https://github.com/n-christie/ahrg_reloc_age_dce/blob/main/latex/elsvier/reloc_age_prospectus.pdf?raw=true)
:::

## Now to our DCE!!

Now we've had a background on DCEs, let's look to what ***we're*** doing.  First the challenges:

- We need to decide on the attribute levels
- We need to work on presenting and defining the attributes so it is clear to the respondents what they are "trading off".
- We need to ensure the instructions are clear and that the experiment is well-defined.  It should be clear that the hypothetical alternatives only differ by the levels of the attributes and are the same in every other way.


## Attributes - where we are at

- Our approach has been to leverage previous housing studies 
- While adding some attributes deemed important from the follow-up study.
- The attributes and levels need to have certain properties to keep us in the Utility theory framework and create feasible choice sets.
- We feel pretty confident with our attributes, we'd like help on the attribute levels!

## Attributes and levels

-   __Distance to green areas__ - 5km, 10km,15km
-   __Distance to services__- 500m, 5km,15km
-   __Distance to transportation__ - 200m, 400m, 800m
-   __Parking__ - Gratis områdesparkering, Betald områdesparkering,  Garage: Betald parkeringsplats inomhus.
-   __Cost__- -20%, -10%, Same, 10%, 20%


## Levels

- Choice between geographical distance (meters or km) or time (5min walking distance)
- Choice in levels - do they make sense?
- What are the most realistic distances for apartment buildings in Sweden?
- It would be convenient if the levels are all the same across the attributes to better compare the results. Realistic?


# Take the [UPDATED SURVEY (In Swedish)!](http://37.27.25.127/reloc-age-dce-swe)

# Break

## Feedback Results

## Discussion - Talking points

## References


